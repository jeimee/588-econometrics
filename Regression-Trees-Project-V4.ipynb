{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Trees\n",
    "### Economics 588\n",
    "##### Jacob Van Leeuwen, John Bonney, Erik Webb, Taylor Landon, Rachel Bagnall, Scott Elliott, Jaimie Choi, Isaac Riley"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction trees are a particular kind of nonlinear predictive model. There are two varieties: regression trees and classification trees. Of course, we will be focused on regression trees. We use linear regression as a method of making quantitative predictions. However, linear regressions do not do well with a nonlinear models. A solution to this problem can be to partition the data into smaller regions where we are able to have more manageable linear interactions. We can recursively subdivide the partitions until we get extremely manageable pieces that can be estimated with simple regression models. This process is known as recursive partitioning. Hence, we use recursive partitioning to sort the data into small, manageable sections and then use a simple model for each part of the partition. \n",
    "\n",
    "We can represent the recursive partitioning process using a regression tree. Thus, each terminal node of the regression tree represents a part of the partition that has an estimate found using a simple model. The estimate found applies only to the specific partition. We navigate the tree by asking a sequence of questions about specific features for some point, x. Each question, usually refers to only a single attribute with a yes or no answer. For example, a question of the type could concern gender of the observation (i.e. is the observation male or not). The variables can be either continuous or discrete (but ordered). \n",
    "\n",
    "For classic regression trees, the model in each cell is just a constant estimate of Y. That is, suppose the points (x1,y1), (x2,y2), …, (xc,yc) are all the samples belonging to the node x. Then our model for x is: $$\\hat{y}=\\frac{1}{c} \\sum_{i=1}^{c}y_i$$ This is the sample mean of the dependent variable in that cell. This is a piecewise-constant model. There are several advantages to the piecewise-constant model:\n",
    "\t\t\t\t\t\n",
    "1. Making predictions is fast, since the calculation process is not complicated\n",
    "2. It’s easy to understand what variables are important in prediction (look at the tree)\n",
    "3. If some data is missing, we might not be able to go all the way down the tree to a leaf, but we can still make a prediction by averaging all the leaves in the subtree we do reach\n",
    "4. The model gives a jagged response, so it can work when the true regression surface is not smooth. If it is smooth, though, the piecewise-constant surface can approximate it arbitrarily closely (with enough leaves)\n",
    "5. There are fast, reliable algorithms to learn these trees \t\t\t\t\t\t\n",
    "\n",
    "One of the problems with recursive partitioning is that we need to balance the informativeness of the partitions with parsimony, so as to not just put every point in its own partition. Similarly, we could just end up putting every point in its own leaf-node, which would not be very useful. A typical stopping criterion is to stop growing the tree when further splits gives less than some minimal amount of extra information, or when they would result in nodes containing less than a small percentage of the total data.  \n",
    "\n",
    "Regression trees can be used to address problems in which we want to predict the value of a continuous variable from a set of continuous and/or categorical variables. \n",
    "\n",
    "Examples:\n",
    "\n",
    "Health (Type II Diabetes)\n",
    "* Does increasing sugar Consumption (avg. grams per day) affect whether you develop type II diabetes? (continuous) \n",
    "* How does increasing weight affect whether you develop type II diabetes? (continuous)\n",
    "* Number of days per week with greater than 30 minutes of exercise (categorical) \n",
    "* Age (continuous)\n",
    "* Parent has diabetes (categorical) \n",
    "* Hours worked/week (continuous)\n",
    "\n",
    "Election outcomes (voter-share) (continuous)\n",
    "* What State/Region tends to have greater voter-share? (categorical)\n",
    "* How much does Campaign spending affect voter-share? (continuous)\n",
    "* Incumbent (categorical)\n",
    "* Political Party (categorical)\n",
    "* GDP Growth (continuous)\n",
    "* General vs. Midterm Election (categorical)\n",
    "\n",
    "Selling prices of single family homes (continuous)\n",
    "* Does increasing Square footage increase prices for single family homes? (continuous)\n",
    "* How much do the Style of home affect the selling price of single family homes? (categorical)\n",
    "* Zip code/county/state/etc. (categorical)\n",
    "* Median income of neighborhood/zip code (if area variable is larger than zip code) (continuous)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea behind regression trees is that each good factor (variable in ML) can be used to make a \"decision\" about the likelihood of an outcome. Each split is called a _node_.\n",
    "\n",
    "For example, to predict whether a customer will buy a certain kind of computer, we might use the following simple decision tree:\n",
    "\n",
    "If we have enough data, we can use to train a model that will be able to use the same general idea to predict outcomes given new (similar) data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the regression tree model is to minimize the sum of squared residuals, as in OLS regression. However, in the regression tree model, we are minimizing the sum of squared residuals for a given tree T.\n",
    "The sum of squared residuals for a tree T is $$S=\\sum_{c\\in terminal nodes(T)}\\sum_{i\\in C}(y_i-m_c)^2$$ where $m_c=\\frac{1}{n_c}\\sum_{i\\in C}y_i$, the prediction for leaf c. We make our splits to minimize S.\n",
    "\n",
    "The Algorithm:\n",
    "1. Start with a single node containing all points. Calculate $m_c$ and S. \n",
    "2. If all the points in the node have the same value for all the independent variables, stop. Otherwise, search over all binary splits of all variables for the one which will reduce S as much as possible. IF the largest decrease in S would be less than some threshold delta, or one of the resulting nodes would contain less than q points, stop. Otherwise, take that split, creating two new nodes.\n",
    "3. In each new node, go back to step 1. \n",
    "\n",
    "A more successful approach to finding regression trees uses the idea of cross-validation. We randomly divide our data into a training set and a testing set, (say, 50% training and 50% testing). We then apply the basic tree-growing algorithm to the training data only, with q = 1 and δ = 0 — that is, we grow the largest tree we can. This is generally going to be too large and will over-fit the data. We then use cross-validation to prune the tree. At each pair of terminal nodes with a common parent, we evaluate the error on the testing data, and see whether the sum of squares would be smaller by remove those two nodes and making their parent a terminal node. This is repeated until pruning no longer improves the error on the testing data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Concept: Gini Impurity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we will start with the simplest case: a classification problem with two outcomes. A common example uses a dataset of passengers on the Titanic to predict who survives.\n",
    "\n",
    "Ideally, we want factors that are as predictive as possible. If men and women are equally likely to survive, the variable can't tell us much (barring interaction with other variables). Fortunately (depending on your perspective, but at least for prediction purposes), it turns out women are more likely than men to survive, so _sex_ will be an important factor in our tree.\n",
    "\n",
    "That means that a node splitting on _sex_ has relatively low Gini impurity. Gini impurity measures the frequency of mislabeling a randomly selected element if it was randomly labeled by the distributions of labels in the subset. A factor with high purity is very predictive of the outcome. Conversely, the impurity of a node would be maximized if equal proportions of its values (males and females here) survived.\n",
    "\n",
    "Gini impurity is formally defined as:\n",
    "\n",
    "$$Gini_{i} = 1 - \\sum_{k=1}^{n}{p_{i,k}^2}$$\n",
    "\n",
    "For example, if it were the case that 70% of the survivors were females, the Gini impurity of the _sex_ node would be: \n",
    "\n",
    "$$1-0.3^2-0.7^2 = 0.42$$\n",
    "\n",
    "Notice that 0.42 is medium probability of mislabelling \n",
    "\n",
    "Now suppose that 50% of the survivors were males, the Gini impurity of the _sex_node would be: \n",
    "\n",
    "$$1-0.5^2-0.5^2 = 0.5$$\n",
    "\n",
    "Notice here that the Gini impurity probability increased when splitting gender by 50 percent.\n",
    "\n",
    "Finally, suppose that only 10% of the survivors were females \n",
    "\n",
    "$$1-0.1^2-0.9^2 = 0.18$$\n",
    "\n",
    "Here, the huge disproportionate categorization allows Gini index to be very low, suggesting very low impurity \n",
    "\n",
    "In general, it makes sense to grow a tree **greedily** - starting with the least impure feature splits, then moving to the next least impure.\n",
    "\n",
    "\n",
    "Overfitting is a major concern with regression trees - you might get great scores within your training set, but then find that it generalizes poorly. As is often the case with decision trees, there is a tradeoff between bias, variance, and overfitting. The shallower the tree, the greater the bias and variance, but this may be preferable to overfitting. There are several hyperparameters you can include in the model to keep this from happening, such as:\n",
    "\n",
    "max depth\n",
    "\n",
    "min_samples_split\n",
    "\n",
    "min_samples_leaf\n",
    "\n",
    "min_weight_fraction_leaf\n",
    "\n",
    "max_leaf_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pros and Cons of Regression Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression trees are among the easiest to visualize of ML models. They are intuitive and not hard to explain, even to someone with little econometrics training. They are computationally efficient and don't have the same problems with missing values, non-numerical or cateorical data, and collinearity.\n",
    "\n",
    "On the downside, they often don't have the highest accuracy in prediction and can be sensitive to minor changes in data. One way to overcome these weaknesses is to use multiple decision trees aggregated (random forests, boosting) or in conjunction with other models (stacking)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "#### Housing Prices: A Kaggle Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training dataset contains 1460 observations and 80 features. Let's start by calling packages needed for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-9b774b8c5e0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Other Packages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "# Core Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# ML Packages\n",
    "from sklearn.linear_model import SGDRegressor, ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, f1_score, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split, learning_curve, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# ML Packages\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, f1_score, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, learning_curve, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Other Packages\n",
    "import graphviz \n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading necessary packages, we divide our sample into our training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_location = \"train.csv\"\n",
    "test_location = \"test.csv\"\n",
    "\n",
    "train = pd.read_csv(train_location)\n",
    "test = pd.read_csv(test_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand what our data looks like, we look at a small subset of the training data to understand our data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll remove 'SalePrice' and 'Id' from the training dataset and log-transform 'SalePrice', which is our target variable of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = train['SalePrice']\n",
    "target_transformed = np.log(target)\n",
    "\n",
    "train = train.drop(['SalePrice', 'Id'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start cleaning, let's develop a better understanding of what the data looks like. It looks like we have information about almost every aspect of a home (and its surrounding property) you could imagine, from commonly cited measures like square-feet and number of bedrooms to more detailed  metrics like the height of the basement or the masonry veneer type. Note that the final column is 'SalePrice', which is the variable we seek to predict. \n",
    "\n",
    "Below is a categorization of the features within the following categories: Sales, General, Location, Property, Interior, Basement, Utilities, Garage, and Exterior. This categorization is a subjective exercise, but it allowed me to become more familiar with the features and create general buckets within the dataset.  \n",
    "\n",
    "**Sale**\n",
    "- SalePrice: the property's sale price in dollars\n",
    "- MoSold: Month Sold\n",
    "- YrSold: Year Sold\n",
    "- SaleType: Type of sale\n",
    "- SaleCondition: Condition of sale\n",
    "\n",
    "**General**\n",
    "- MSSubClass: The building class\n",
    "- MSZoning: The general zoning classification\n",
    "- BldgType: Type of dwelling\n",
    "- HouseStyle: Style of dwelling\n",
    "- OverallQual: Overall material and finish quality\n",
    "- OverallCond: Overall condition rating\n",
    "- YearBuilt: Original construction date\n",
    "- YearRemodAdd: Remodel date\n",
    "- MiscFeature: Miscellaneous feature not covered in other categories\n",
    "- MiscVal: Dollar Value of miscellaneous feature\n",
    "\n",
    "**Location**\n",
    "- Street: Type of road access\n",
    "- Alley: Type of alley access\n",
    "- Neighborhood: Physical locations within Ames city limits\n",
    "- Condition1: Proximity to main road or railroad\n",
    "- Condition2: Proximity to main road or railroad (if a second is present)\n",
    "- LotFrontage: Linear feet of street connected to property\n",
    "\n",
    "**Property**\n",
    "- LotArea: Lot size in square feet\n",
    "- LotShape: General shape of property\n",
    "- LandContour: Flatness of the property\n",
    "- LotConfig: Lot configuration\n",
    "- LandSlope: Slope of property\n",
    "\n",
    "**Interior**\n",
    "- 1stFlrSF: First Floor square feet\n",
    "- 2ndFlrSF: Second floor square feet\n",
    "- LowQualFinSF: Low quality finished square feet (all floors)\n",
    "- GrLivArea: Above grade (ground) living area square feet\n",
    "- FullBath: Full bathrooms above grade\n",
    "- HalfBath: Half baths above grade\n",
    "- Bedroom: Number of bedrooms above basement level\n",
    "- Kitchen: Number of kitchens\n",
    "- KitchenQual: Kitchen quality\n",
    "- TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n",
    "- Functional: Home functionality rating\n",
    "- Fireplaces: Number of fireplaces\n",
    "- FireplaceQu: Fireplace quality\n",
    "\n",
    "**Basement**\n",
    "- BsmtQual: Height of the basement\n",
    "- BsmtCond: General condition of the basement\n",
    "- BsmtExposure: Walkout or garden level basement walls\n",
    "- BsmtFinType1: Quality of basement finished area\n",
    "- BsmtFinSF1: Type 1 finished square feet\n",
    "- BsmtFinType2: Quality of second finished area (if present)\n",
    "- BsmtFinSF2: Type 2 finished square feet\n",
    "- BsmtUnfSF: Unfinished square feet of basement area\n",
    "- TotalBsmtSF: Total square feet of basement area\n",
    "- BsmtFullBath: Basement full bathrooms\n",
    "- BsmtHalfBath: Basement half bathrooms\n",
    "\n",
    "**Utilities**\n",
    "- Utilities: Type of utilities available\n",
    "- Heating: Type of heating\n",
    "- HeatingQC: Heating quality and condition\n",
    "- CentralAir: Central air conditioning\n",
    "- Electrical: Electrical system\n",
    "\n",
    "**Garage**\n",
    "- GarageType: Garage location\n",
    "- GarageYrBlt: Year garage was built\n",
    "- GarageFinish: Interior finish of the garage\n",
    "- GarageCars: Size of garage in car capacity\n",
    "- GarageArea: Size of garage in square feet\n",
    "- GarageQual: Garage quality\n",
    "- GarageCond: Garage condition\n",
    "\n",
    "**Exterior**\n",
    "- RoofStyle: Type of roof\n",
    "- RoofMatl: Roof material\n",
    "- Exterior1st: Exterior covering on house\n",
    "- Exterior2nd: Exterior covering on house (if more than one material)\n",
    "- MasVnrType: Masonry veneer type\n",
    "- MasVnrArea: Masonry veneer area in square feet\n",
    "- ExterQual: Exterior material quality\n",
    "- ExterCond: Present condition of the material on the exterior\n",
    "- Foundation: Type of foundation\n",
    "- PavedDrive: Paved driveway\n",
    "- WoodDeckSF: Wood deck area in square feet\n",
    "- OpenPorchSF: Open porch area in square feet\n",
    "- EnclosedPorch: Enclosed porch area in square feet\n",
    "- 3SsnPorch: Three season porch area in square feet\n",
    "- ScreenPorch: Screen porch area in square feet\n",
    "- PoolArea: Pool area in square feet\n",
    "- PoolQC: Pool quality\n",
    "- Fence: Fence quality\n",
    "\n",
    "Note that these features are a mix of continuous (Lot Area, Year Built, Bedrooms) and categorical (House Style, Roof Style, Garage Type) variables. \n",
    "\n",
    "Let's start cleaning by checking for missing values. Below we find the number of missing values for each feature, for features with missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Missing Values</th>\n",
       "      <th>Percent Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PoolQC</th>\n",
       "      <td>1453</td>\n",
       "      <td>0.995205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscFeature</th>\n",
       "      <td>1406</td>\n",
       "      <td>0.963014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alley</th>\n",
       "      <td>1369</td>\n",
       "      <td>0.937671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fence</th>\n",
       "      <td>1179</td>\n",
       "      <td>0.807534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FireplaceQu</th>\n",
       "      <td>690</td>\n",
       "      <td>0.472603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>259</td>\n",
       "      <td>0.177397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageType</th>\n",
       "      <td>81</td>\n",
       "      <td>0.055479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>81</td>\n",
       "      <td>0.055479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageFinish</th>\n",
       "      <td>81</td>\n",
       "      <td>0.055479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageQual</th>\n",
       "      <td>81</td>\n",
       "      <td>0.055479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCond</th>\n",
       "      <td>81</td>\n",
       "      <td>0.055479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtExposure</th>\n",
       "      <td>38</td>\n",
       "      <td>0.026027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <td>38</td>\n",
       "      <td>0.026027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <td>37</td>\n",
       "      <td>0.025342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtCond</th>\n",
       "      <td>37</td>\n",
       "      <td>0.025342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtQual</th>\n",
       "      <td>37</td>\n",
       "      <td>0.025342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>8</td>\n",
       "      <td>0.005479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrType</th>\n",
       "      <td>8</td>\n",
       "      <td>0.005479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electrical</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Number of Missing Values  Percent Missing\n",
       "PoolQC                            1453         0.995205\n",
       "MiscFeature                       1406         0.963014\n",
       "Alley                             1369         0.937671\n",
       "Fence                             1179         0.807534\n",
       "FireplaceQu                        690         0.472603\n",
       "LotFrontage                        259         0.177397\n",
       "GarageType                          81         0.055479\n",
       "GarageYrBlt                         81         0.055479\n",
       "GarageFinish                        81         0.055479\n",
       "GarageQual                          81         0.055479\n",
       "GarageCond                          81         0.055479\n",
       "BsmtExposure                        38         0.026027\n",
       "BsmtFinType2                        38         0.026027\n",
       "BsmtFinType1                        37         0.025342\n",
       "BsmtCond                            37         0.025342\n",
       "BsmtQual                            37         0.025342\n",
       "MasVnrArea                           8         0.005479\n",
       "MasVnrType                           8         0.005479\n",
       "Electrical                           1         0.000685"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of missing values for each feature, including only those greater than 0. \n",
    "missing_values = pd.DataFrame(train.isnull().sum())\n",
    "missing_values = missing_values[(missing_values > 0).any(axis=1)]\n",
    "\n",
    "# Sort the values in ascending order. \n",
    "missing_values = missing_values.sort_values(by = 0, ascending = False)\n",
    "missing_values.columns = ['Number of Missing Values']\n",
    "\n",
    "# Calculate 'Percent Missing'\n",
    "missing_values['Percent Missing'] = missing_values['Number of Missing Values']/len(train)\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19 of the 80 features are missing 1 or more value. However, the degree to which values are missing varies widely across the 19 variables. Only 7 of the 1460 properties have information about pool quality ('PoolQC') while only 1 property is missing information about the property's electrical system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll drop 'Alley', 'FireplaceQu', 'PoolQC', 'PoolArea', 'Fence', and 'MiscFeature' from our dataset, since most observations do not have information for those variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop(['MiscFeature', 'Fence', 'PoolQC', 'PoolArea', 'FireplaceQu', 'Alley'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the others? Let's fill them in with the average of the feature if the feature is continuous or with the mode if the feature is categorical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for feature in train:\n",
    "   # Features with a 'dtype' of O are categorical \n",
    "    if train[feature].dtype == 'O':\n",
    "       train[feature] = train[feature].fillna(train[feature].mode()[0])\n",
    "\n",
    "for feature in train:\n",
    "   # Features with a 'dtype' of i or are floats are continuous\n",
    "    if train[feature].dtype == np.float64 or train[feature].dtype == 'i':\n",
    "       train[feature] = train[feature].fillna(train[feature].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm there aren't any remaining missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should return 'False'\n",
    "train.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next look at outliers. To start, we'll explicitly determine which of our features are categorical and which are continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Continuous Features: 35 \n",
      "Number of Categorical Features: 38\n"
     ]
    }
   ],
   "source": [
    "# Create two empty lists\n",
    "continuous_features = []\n",
    "categorical_features = []\n",
    "\n",
    "# Seperate features by dtype\n",
    "for feature in train.columns:\n",
    "    if train[feature].dtype == \"object\":\n",
    "        categorical_features.append(feature)\n",
    "    else:\n",
    "        continuous_features.append(feature)\n",
    "        \n",
    "print(\"Number of Continuous Features:\", len(continuous_features), \"\\nNumber of Categorical Features:\", len(categorical_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use this to filter outliers according to a simple rule: \n",
    "\n",
    "For each column we compute the z-score of each value in the column relative to the column mean and standard deviation. Since the direction of the difference is irrelevant, we take the absolute value. Here we remove rows that contain a (continuous) feature value greater than 5 standard deviations away from the standardized mean. \n",
    "\n",
    "This code below was adapted from [this](https://stackoverflow.com/questions/23199796/detect-and-exclude-outliers-in-pandas-dataframe) Stack Overflow article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_std = 5\n",
    "len(train) - len(train[train[continuous_features].apply(lambda x: np.abs(x - x.mean()) / x.std() < n_std).all(axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In doing so we drop 86 rows of our training data. We can adjust this threshold later to see if it affects our mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop rows in training set (and target) according to the rule described above\n",
    "target_transformed = target_transformed[train[continuous_features].apply(lambda x: np.abs(x - x.mean()) / x.std() < 10).all(axis=1)]\n",
    "train = train[train[continuous_features].apply(lambda x: np.abs(x - x.mean()) / x.std() < 10).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step of the cleaning process is to create dummy variables for the categorical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_no_dummies = train\n",
    "train = pd.get_dummies(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the same changes we made, cleaning missing values, checking for outliers, and getting dummies for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.drop(['MiscFeature', 'Fence', 'PoolQC', 'FireplaceQu', 'Alley'], axis = 1)\n",
    "\n",
    "for feature in test:\n",
    "    # Features with a 'dtype' of O are categorical \n",
    "   if test[feature].dtype == 'O':\n",
    "       test[feature] = test[feature].fillna(test[feature].mode()[0])\n",
    "for feature in test:\n",
    "    # Features with a 'dtype' of i or are floats are continuous\n",
    "    if test[feature].dtype == np.float64 or test[feature].dtype == 'i':\n",
    "       test[feature] = test[feature].fillna(test[feature].mean())\n",
    "\n",
    "# Only keep columns in test that are also found in train\n",
    "test = test.reindex(columns = train.columns, fill_value=0)\n",
    "\n",
    "test_no_dummies = test\n",
    "test = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Exploration & Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data cleaned we're now ready to explore the data. We begin by calculating the correlations for all of the continuous features and ranking them from -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Correlation with SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>TotalBsmtSF</td>\n",
       "      <td>0.642681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>GarageArea</td>\n",
       "      <td>0.656542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GarageCars</td>\n",
       "      <td>0.681622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>GrLivArea</td>\n",
       "      <td>0.718890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>OverallQual</td>\n",
       "      <td>0.820278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature  Correlation with SalePrice\n",
       "30  TotalBsmtSF                    0.642681\n",
       "31   GarageArea                    0.656542\n",
       "32   GarageCars                    0.681622\n",
       "33    GrLivArea                    0.718890\n",
       "34  OverallQual                    0.820278"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out categorical variables\n",
    "values = []\n",
    "df = train[continuous_features]\n",
    "\n",
    "# Iterate over each continous feature and calcualte its correlation with the target\n",
    "for feature in df.columns:\n",
    "    values.append([feature, df[feature].corr(target_transformed)])\n",
    "    \n",
    "# Sort the values and present them in a Pandas Dataframe\n",
    "values = sorted(values, key=lambda x: x[1])\n",
    "correlations = pd.DataFrame(values, columns = ['Feature', 'Correlation with SalePrice'])\n",
    "correlations.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like 'OverallQual', 'GrLivArea' 'GarageCars', 'GarageArea', 'TotalBsmtSF' and '1stFlrSF' are moderately to highly correlated with 'SalePrice'. We'll need to examine the coefficients on these features when we do model fitting later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Fitting & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our modeling, we will use the technigues described in the analytical framework to estimate a regression tree model that estimates the log of hose prices for homes in the Kaggle dataset. We will estimate both a full regression tree that includes all possible variables, as well as a simpler regression tree that gives a better visual and conceptual representation of how regression trees work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Regression Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we begin by scaling the training and test data and confirming that the matrices have the correct shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scale the training data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train)\n",
    "scaled_train_df = scaler.transform(train)\n",
    "\n",
    "# Scale the test data\n",
    "scaler.fit(test)\n",
    "scaled_test_df = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data sets are correctly shaped, the training and test sets should have the same number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1443,) (1443, 267) (1459, 267)\n"
     ]
    }
   ],
   "source": [
    "print(target_transformed.shape, scaled_train_df.shape, scaled_test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare our testing and training datasets for our regression tree model, and we determine the best parameters to use in our analysis using a grid search cross-validation method. We also fit our model to the training data, and generate predictions for both the training data and the test data. We also report what hyperparameters we use based on our cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'max_depth': 25, 'min_samples_leaf': 5}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_train_df, target_transformed, test_size=0.33, random_state=42)\n",
    "\n",
    "param_dist = {\"min_samples_leaf\": [3, 5, 8], \"max_depth\": [15, 20, 25, 30]}\n",
    "model = DecisionTreeRegressor()\n",
    "dt = GridSearchCV(model, param_grid=param_dist, scoring='neg_mean_squared_error')\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "dt_train_predictions = dt.predict(X_train)\n",
    "dt_test_predictions = dt.predict(X_test)\n",
    "print(\"Best Params: {}\".format(dt.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small Regression Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replicate the full decision tree with a subset of the variables to show a more concise and easy to understand example of how regression trees work. In particular, we use a subset of variables that are likely to be the most salient for homebuyers to consider when purchasing a home. The variables we include are total square footage, overall quality, overall condition, lot size, the year the home was built, as well as the number of bedrooms and bathrooms. We subset both the training data and the test data by these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the training data\n",
    "s_train = train_no_dummies\n",
    "s_train['TotalSF'] = train_no_dummies['TotalBsmtSF'] + train_no_dummies['1stFlrSF'] + train_no_dummies['2ndFlrSF']\n",
    "s_train = s_train[['TotalSF', 'OverallQual', 'OverallCond', 'LotArea', 'YearBuilt', 'BedroomAbvGr', 'FullBath', 'HalfBath']]\n",
    "\n",
    "# Prepare the test data\n",
    "s_test = test_no_dummies\n",
    "s_test['TotalSF'] = test_no_dummies['TotalBsmtSF'] + test_no_dummies['1stFlrSF'] + test_no_dummies['2ndFlrSF']\n",
    "s_test = s_test[['TotalSF', 'OverallQual', 'OverallCond', 'LotArea', 'YearBuilt', 'BedroomAbvGr', 'FullBath', 'HalfBath']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the full regression tree, we scale the test data and the training data to prepare it for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scale the training data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(s_train)\n",
    "scaled_s_train_df = scaler.transform(s_train)\n",
    "\n",
    "# Scale the test data\n",
    "scaler.fit(s_test)\n",
    "scaled_s_test_df = scaler.transform(s_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit our model with our training data to a regression tree with a maximum depth of 3, and we generate a set of predictions for both our training data and our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(s_train, target_transformed, test_size=0.33, random_state=42)\n",
    "\n",
    "clf = DecisionTreeRegressor(max_depth = 3)  \n",
    "clf = clf.fit(X_train, y_train)\n",
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a visual representation of this simplified regression tree using the \"graphviz\" package. The visualization shows the leaves and branches of our regression tree model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"658pt\" height=\"358pt\"\n",
       " viewBox=\"0.00 0.00 658.30 358.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 354)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-354 654.3042,-354 654.3042,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.450980\" stroke=\"#000000\" d=\"M379.4047,-350C379.4047,-350 270.3834,-350 270.3834,-350 264.3834,-350 258.3834,-344 258.3834,-338 258.3834,-338 258.3834,-298 258.3834,-298 258.3834,-292 264.3834,-286 270.3834,-286 270.3834,-286 379.4047,-286 379.4047,-286 385.4047,-286 391.4047,-292 391.4047,-298 391.4047,-298 391.4047,-338 391.4047,-338 391.4047,-344 385.4047,-350 379.4047,-350\"/>\n",
       "<text text-anchor=\"middle\" x=\"324.894\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">OverallQual &lt;= 6.5</text>\n",
       "<text text-anchor=\"middle\" x=\"324.894\" y=\"-320.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 0.152</text>\n",
       "<text text-anchor=\"middle\" x=\"324.894\" y=\"-306.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 100.0%</text>\n",
       "<text text-anchor=\"middle\" x=\"324.894\" y=\"-292.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 12.005</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.309804\" stroke=\"#000000\" d=\"M303.3078,-250C303.3078,-250 196.4803,-250 196.4803,-250 190.4803,-250 184.4803,-244 184.4803,-238 184.4803,-238 184.4803,-198 184.4803,-198 184.4803,-192 190.4803,-186 196.4803,-186 196.4803,-186 303.3078,-186 303.3078,-186 309.3078,-186 315.3078,-192 315.3078,-198 315.3078,-198 315.3078,-238 315.3078,-238 315.3078,-244 309.3078,-250 303.3078,-250\"/>\n",
       "<text text-anchor=\"middle\" x=\"249.894\" y=\"-234.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">TotalSF &lt;= 2102.0</text>\n",
       "<text text-anchor=\"middle\" x=\"249.894\" y=\"-220.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">0.083</text>\n",
       "<text text-anchor=\"middle\" x=\"249.894\" y=\"-206.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">63.9%</text>\n",
       "<text text-anchor=\"middle\" x=\"249.894\" y=\"-192.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">11.808</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M300.7507,-285.8089C294.1936,-277.0661 287.0098,-267.4876 280.1605,-258.3553\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"282.7922,-256.0308 273.9921,-250.1308 277.1921,-260.2308 282.7922,-256.0308\"/>\n",
       "<text text-anchor=\"middle\" x=\"270.4566\" y=\"-270.6795\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.701961\" stroke=\"#000000\" d=\"M453.3078,-250C453.3078,-250 346.4803,-250 346.4803,-250 340.4803,-250 334.4803,-244 334.4803,-238 334.4803,-238 334.4803,-198 334.4803,-198 334.4803,-192 340.4803,-186 346.4803,-186 346.4803,-186 453.3078,-186 453.3078,-186 459.3078,-186 465.3078,-192 465.3078,-198 465.3078,-198 465.3078,-238 465.3078,-238 465.3078,-244 459.3078,-250 453.3078,-250\"/>\n",
       "<text text-anchor=\"middle\" x=\"399.894\" y=\"-234.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">TotalSF &lt;= 3002.0</text>\n",
       "<text text-anchor=\"middle\" x=\"399.894\" y=\"-220.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">0.087</text>\n",
       "<text text-anchor=\"middle\" x=\"399.894\" y=\"-206.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">36.1%</text>\n",
       "<text text-anchor=\"middle\" x=\"399.894\" y=\"-192.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">12.352</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M349.0373,-285.8089C355.5945,-277.0661 362.7783,-267.4876 369.6275,-258.3553\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"372.5959,-260.2308 375.796,-250.1308 366.9959,-256.0308 372.5959,-260.2308\"/>\n",
       "<text text-anchor=\"middle\" x=\"379.3315\" y=\"-270.6795\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.176471\" stroke=\"#000000\" d=\"M153.3078,-150C153.3078,-150 46.4803,-150 46.4803,-150 40.4803,-150 34.4803,-144 34.4803,-138 34.4803,-138 34.4803,-98 34.4803,-98 34.4803,-92 40.4803,-86 46.4803,-86 46.4803,-86 153.3078,-86 153.3078,-86 159.3078,-86 165.3078,-92 165.3078,-98 165.3078,-98 165.3078,-138 165.3078,-138 165.3078,-144 159.3078,-150 153.3078,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"99.894\" y=\"-134.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">TotalSF &lt;= 1618.0</text>\n",
       "<text text-anchor=\"middle\" x=\"99.894\" y=\"-120.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">0.069</text>\n",
       "<text text-anchor=\"middle\" x=\"99.894\" y=\"-106.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">28.5%</text>\n",
       "<text text-anchor=\"middle\" x=\"99.894\" y=\"-92.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">11.621</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M201.6074,-185.8089C187.2888,-176.2632 171.4759,-165.7213 156.6714,-155.8516\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"158.3522,-152.7656 148.0902,-150.1308 154.4692,-158.59 158.3522,-152.7656\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.419608\" stroke=\"#000000\" d=\"M304.4047,-150C304.4047,-150 195.3834,-150 195.3834,-150 189.3834,-150 183.3834,-144 183.3834,-138 183.3834,-138 183.3834,-98 183.3834,-98 183.3834,-92 189.3834,-86 195.3834,-86 195.3834,-86 304.4047,-86 304.4047,-86 310.4047,-86 316.4047,-92 316.4047,-98 316.4047,-98 316.4047,-138 316.4047,-138 316.4047,-144 310.4047,-150 304.4047,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"249.894\" y=\"-134.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">OverallQual &lt;= 5.5</text>\n",
       "<text text-anchor=\"middle\" x=\"249.894\" y=\"-120.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">0.043</text>\n",
       "<text text-anchor=\"middle\" x=\"249.894\" y=\"-106.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">35.4%</text>\n",
       "<text text-anchor=\"middle\" x=\"249.894\" y=\"-92.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">11.959</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M249.894,-185.8089C249.894,-177.6906 249.894,-168.8517 249.894,-160.3186\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"253.3941,-160.1307 249.894,-150.1308 246.3941,-160.1308 253.3941,-160.1307\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"transparent\" stroke=\"#000000\" d=\"M45.6825,-50C45.6825,-50 12.1056,-50 12.1056,-50 6.1056,-50 .1056,-44 .1056,-38 .1056,-38 .1056,-12 .1056,-12 .1056,-6 6.1056,0 12.1056,0 12.1056,0 45.6825,0 45.6825,0 51.6825,0 57.6825,-6 57.6825,-12 57.6825,-12 57.6825,-38 57.6825,-38 57.6825,-44 51.6825,-50 45.6825,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"28.894\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">0.083</text>\n",
       "<text text-anchor=\"middle\" x=\"28.894\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">7.1%</text>\n",
       "<text text-anchor=\"middle\" x=\"28.894\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">11.375</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M75.4599,-85.9947C68.5805,-76.9837 61.0852,-67.1658 54.1583,-58.0927\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"56.8409,-55.8386 47.9908,-50.014 51.277,-60.0863 56.8409,-55.8386\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.235294\" stroke=\"#000000\" d=\"M121.6825,-50C121.6825,-50 88.1056,-50 88.1056,-50 82.1056,-50 76.1056,-44 76.1056,-38 76.1056,-38 76.1056,-12 76.1056,-12 76.1056,-6 82.1056,0 88.1056,0 88.1056,0 121.6825,0 121.6825,0 127.6825,0 133.6825,-6 133.6825,-12 133.6825,-12 133.6825,-38 133.6825,-38 133.6825,-44 127.6825,-50 121.6825,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"104.894\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">0.037</text>\n",
       "<text text-anchor=\"middle\" x=\"104.894\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">21.3%</text>\n",
       "<text text-anchor=\"middle\" x=\"104.894\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">11.703</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M101.6148,-85.9947C102.0646,-77.6273 102.5519,-68.5643 103.0098,-60.0478\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"106.5072,-60.1875 103.5492,-50.014 99.5173,-59.8117 106.5072,-60.1875\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.349020\" stroke=\"#000000\" d=\"M229.6825,-50C229.6825,-50 196.1056,-50 196.1056,-50 190.1056,-50 184.1056,-44 184.1056,-38 184.1056,-38 184.1056,-12 184.1056,-12 184.1056,-6 190.1056,0 196.1056,0 196.1056,0 229.6825,0 229.6825,0 235.6825,0 241.6825,-6 241.6825,-12 241.6825,-12 241.6825,-38 241.6825,-38 241.6825,-44 235.6825,-50 229.6825,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"212.894\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">0.038</text>\n",
       "<text text-anchor=\"middle\" x=\"212.894\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">15.7%</text>\n",
       "<text text-anchor=\"middle\" x=\"212.894\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">11.863</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M237.1607,-85.9947C233.7586,-77.4434 230.0674,-68.1656 226.6147,-59.487\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"229.7947,-58.0118 222.8459,-50.014 223.2905,-60.5995 229.7947,-58.0118\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.474510\" stroke=\"#000000\" d=\"M306.2146,-50C306.2146,-50 271.5735,-50 271.5735,-50 265.5735,-50 259.5735,-44 259.5735,-38 259.5735,-38 259.5735,-12 259.5735,-12 259.5735,-6 265.5735,0 271.5735,0 271.5735,0 306.2146,0 306.2146,0 312.2146,0 318.2146,-6 318.2146,-12 318.2146,-12 318.2146,-38 318.2146,-38 318.2146,-44 312.2146,-50 306.2146,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.894\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">0.033</text>\n",
       "<text text-anchor=\"middle\" x=\"288.894\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">19.7%</text>\n",
       "<text text-anchor=\"middle\" x=\"288.894\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">12.036</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M263.3156,-85.9947C266.9016,-77.4434 270.7924,-68.1656 274.4317,-59.487\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"277.7646,-60.5895 278.4043,-50.014 271.3093,-57.8824 277.7646,-60.5895\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.560784\" stroke=\"#000000\" d=\"M453.3078,-150C453.3078,-150 346.4803,-150 346.4803,-150 340.4803,-150 334.4803,-144 334.4803,-138 334.4803,-138 334.4803,-98 334.4803,-98 334.4803,-92 340.4803,-86 346.4803,-86 346.4803,-86 453.3078,-86 453.3078,-86 459.3078,-86 465.3078,-92 465.3078,-98 465.3078,-98 465.3078,-138 465.3078,-138 465.3078,-144 459.3078,-150 453.3078,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"399.894\" y=\"-134.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">TotalSF &lt;= 2535.0</text>\n",
       "<text text-anchor=\"middle\" x=\"399.894\" y=\"-120.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">0.029</text>\n",
       "<text text-anchor=\"middle\" x=\"399.894\" y=\"-106.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">18.5%</text>\n",
       "<text text-anchor=\"middle\" x=\"399.894\" y=\"-92.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">12.155</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M399.894,-185.8089C399.894,-177.6906 399.894,-168.8517 399.894,-160.3186\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"403.3941,-160.1307 399.894,-150.1308 396.3941,-160.1308 403.3941,-160.1307\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.850980\" stroke=\"#000000\" d=\"M601.3078,-150C601.3078,-150 494.4803,-150 494.4803,-150 488.4803,-150 482.4803,-144 482.4803,-138 482.4803,-138 482.4803,-98 482.4803,-98 482.4803,-92 488.4803,-86 494.4803,-86 494.4803,-86 601.3078,-86 601.3078,-86 607.3078,-86 613.3078,-92 613.3078,-98 613.3078,-98 613.3078,-138 613.3078,-138 613.3078,-144 607.3078,-150 601.3078,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"547.894\" y=\"-134.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">TotalSF &lt;= 3602.0</text>\n",
       "<text text-anchor=\"middle\" x=\"547.894\" y=\"-120.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">0.064</text>\n",
       "<text text-anchor=\"middle\" x=\"547.894\" y=\"-106.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">17.6%</text>\n",
       "<text text-anchor=\"middle\" x=\"547.894\" y=\"-92.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">12.558</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>8&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M447.5368,-185.8089C461.6645,-176.2632 477.2666,-165.7213 491.8737,-155.8516\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"494.0141,-158.6294 500.3405,-150.1308 490.0951,-152.8293 494.0141,-158.6294\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.486275\" stroke=\"#000000\" d=\"M399.2146,-50C399.2146,-50 364.5735,-50 364.5735,-50 358.5735,-50 352.5735,-44 352.5735,-38 352.5735,-38 352.5735,-12 352.5735,-12 352.5735,-6 358.5735,0 364.5735,0 364.5735,0 399.2146,0 399.2146,0 405.2146,0 411.2146,-6 411.2146,-12 411.2146,-12 411.2146,-38 411.2146,-38 411.2146,-44 405.2146,-50 399.2146,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"381.894\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">0.016</text>\n",
       "<text text-anchor=\"middle\" x=\"381.894\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">7.7%</text>\n",
       "<text text-anchor=\"middle\" x=\"381.894\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">12.053</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M393.6995,-85.9947C392.08,-77.6273 390.3258,-68.5643 388.6775,-60.0478\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"392.072,-59.1667 386.7355,-50.014 385.1995,-60.4969 392.072,-59.1667\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.611765\" stroke=\"#000000\" d=\"M476.2146,-50C476.2146,-50 441.5735,-50 441.5735,-50 435.5735,-50 429.5735,-44 429.5735,-38 429.5735,-38 429.5735,-12 429.5735,-12 429.5735,-6 435.5735,0 441.5735,0 441.5735,0 476.2146,0 476.2146,0 482.2146,0 488.2146,-6 488.2146,-12 488.2146,-12 488.2146,-38 488.2146,-38 488.2146,-44 482.2146,-50 476.2146,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"458.894\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">0.026</text>\n",
       "<text text-anchor=\"middle\" x=\"458.894\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">10.9%</text>\n",
       "<text text-anchor=\"middle\" x=\"458.894\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">12.227</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>9&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M420.1985,-85.9947C425.7985,-77.1676 431.8897,-67.5662 437.5468,-58.6491\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"440.6233,-60.3331 443.0249,-50.014 434.7124,-56.5832 440.6233,-60.3331\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.772549\" stroke=\"#000000\" d=\"M561.2146,-50C561.2146,-50 526.5735,-50 526.5735,-50 520.5735,-50 514.5735,-44 514.5735,-38 514.5735,-38 514.5735,-12 514.5735,-12 514.5735,-6 520.5735,0 526.5735,0 526.5735,0 561.2146,0 561.2146,0 567.2146,0 573.2146,-6 573.2146,-12 573.2146,-12 573.2146,-38 573.2146,-38 573.2146,-44 567.2146,-50 561.2146,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"543.894\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">0.028</text>\n",
       "<text text-anchor=\"middle\" x=\"543.894\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">11.7%</text>\n",
       "<text text-anchor=\"middle\" x=\"543.894\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">12.453</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M546.5175,-85.9947C546.1576,-77.6273 545.7678,-68.5643 545.4015,-60.0478\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"548.8965,-59.8544 544.9699,-50.014 541.903,-60.1552 548.8965,-59.8544\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<path fill=\"#e58139\" stroke=\"#000000\" d=\"M638.2146,-50C638.2146,-50 603.5735,-50 603.5735,-50 597.5735,-50 591.5735,-44 591.5735,-38 591.5735,-38 591.5735,-12 591.5735,-12 591.5735,-6 597.5735,0 603.5735,0 603.5735,0 638.2146,0 638.2146,0 644.2146,0 650.2146,-6 650.2146,-12 650.2146,-12 650.2146,-38 650.2146,-38 650.2146,-44 644.2146,-50 638.2146,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"620.894\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">0.068</text>\n",
       "<text text-anchor=\"middle\" x=\"620.894\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">5.9%</text>\n",
       "<text text-anchor=\"middle\" x=\"620.894\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">12.768</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>12&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M573.0165,-85.9947C580.0896,-76.9837 587.7961,-67.1658 594.9181,-58.0927\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"597.838,-60.0413 601.2594,-50.014 592.3317,-55.7191 597.838,-60.0413\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1a174dc358>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\n",
    "dot_data = tree.export_graphviz(clf, out_file = None, feature_names = s_train.columns, label = 'root', filled = True, impurity = True, proportion = True, rounded = True)\n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also report a portion of our results, including the actual sale price and the predicted sale price for the first 20 observations in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105000.0</td>\n",
       "      <td>120967.531328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>183000.0</td>\n",
       "      <td>171538.466719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138000.0</td>\n",
       "      <td>141854.736477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>176500.0</td>\n",
       "      <td>168797.484457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79000.0</td>\n",
       "      <td>120967.531328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>98600.0</td>\n",
       "      <td>141854.736477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>170000.0</td>\n",
       "      <td>171538.466719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>272000.0</td>\n",
       "      <td>168797.484457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>125000.0</td>\n",
       "      <td>120967.531328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>160000.0</td>\n",
       "      <td>168797.484457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>186500.0</td>\n",
       "      <td>168797.484457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>135500.0</td>\n",
       "      <td>141854.736477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>119500.0</td>\n",
       "      <td>120967.531328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>197900.0</td>\n",
       "      <td>204327.189729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>147400.0</td>\n",
       "      <td>171538.466719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>239000.0</td>\n",
       "      <td>204327.189729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>131000.0</td>\n",
       "      <td>141854.736477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>269790.0</td>\n",
       "      <td>255907.783494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>112000.0</td>\n",
       "      <td>141854.736477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>130000.0</td>\n",
       "      <td>204327.189729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual      Predicted\n",
       "0   105000.0  120967.531328\n",
       "1   183000.0  171538.466719\n",
       "2   138000.0  141854.736477\n",
       "3   176500.0  168797.484457\n",
       "4    79000.0  120967.531328\n",
       "5    98600.0  141854.736477\n",
       "6   170000.0  171538.466719\n",
       "7   272000.0  168797.484457\n",
       "8   125000.0  120967.531328\n",
       "9   160000.0  168797.484457\n",
       "10  186500.0  168797.484457\n",
       "11  135500.0  141854.736477\n",
       "12  119500.0  120967.531328\n",
       "13  197900.0  204327.189729\n",
       "14  147400.0  171538.466719\n",
       "15  239000.0  204327.189729\n",
       "16  131000.0  141854.736477\n",
       "17  269790.0  255907.783494\n",
       "18  112000.0  141854.736477\n",
       "19  130000.0  204327.189729"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\"Actual\": np.exp(y_train), \"Predicted\": list(np.exp(clf.predict(X_train)))})\n",
    "results = results.reset_index(drop=True)\n",
    "results.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
